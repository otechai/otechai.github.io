[{"content":"Google\u0026rsquo;s Hidden Empire: When \u0026ldquo;Don\u0026rsquo;t Be Evil\u0026rdquo; Built 6,000 Tentacles Here\u0026rsquo;s a question that should keep you up at night: What if the most powerful company in digital history isn\u0026rsquo;t just buying competitorsâ€”it\u0026rsquo;s building an invisible web of dependencies that regulators can\u0026rsquo;t even see?\nThree researchers just dropped a bombshell paper revealing that Google has quietly amassed control over nearly 6,000 companies through investments and \u0026ldquo;support.\u0026rdquo; Not acquisitions. Support. Like a friendly neighborhood loan shark, except the neighborhood is the entire internet and the \u0026ldquo;loan\u0026rdquo; comes with strings attached to your innovation pipeline.\nLet me translate what they found, because this is where it gets properly disturbing.\nThe Shell Game You know how everyone\u0026rsquo;s been watching big tech acquisitions? Facebook buying Instagram, Microsoft buying LinkedIn, that kind of thing? Turns out we\u0026rsquo;ve been watching the wrong game entirely.\nGoogle made about 250 acquisitions since 2004. Regulators reviewed exactly four of them. That\u0026rsquo;s less than two percent. Already concerning, right? But here\u0026rsquo;s the kicker: while everyone was watching those acquisitions, Google shifted strategies entirely. Between 2010 and 2024, its acquisitions dropped while its investments explodedâ€”from 20 investments in 2010 to over 700 annually by 2022.\nThey call this \u0026ldquo;venture capital support\u0026rdquo; and \u0026ldquo;accelerator programs.\u0026rdquo; Here\u0026rsquo;s what that really means: Google identifies promising startups, gives them money or free cloud credits, embeds itself in their operations, shapes their business plans, and creates a galaxy of companies that orbit Google\u0026rsquo;s interests. No acquisition necessary. No regulatory review triggered.\nThe other big tech companies combinedâ€”Amazon, Apple, Meta, Microsoftâ€”invested in about 3,500 companies over this period. Google alone? Nearly 6,000.\nThink about that structure. It\u0026rsquo;s like comparing a traditional monopoly (one big company dominating a market) to a mafia family (one organization controlling hundreds of seemingly independent businesses). Regulators know how to fight the first one. The second? They\u0026rsquo;re barely aware it exists.\nThe Original Sin: DoubleClick To understand how we got here, we need to talk about Google\u0026rsquo;s 2007 acquisition of DoubleClick. This is the Rosetta Stone for understanding everything that followed.\nDoubleClick was an advertising technology company that sat between advertisers and publishers. Before Google bought it, lots of smart people warned regulators: \u0026ldquo;This is dangerous. Google will use this to monopolize digital advertising.\u0026rdquo;\nThe Federal Trade Commission and European Commission waved it through. Why? Because they used something called Industrial Organization economicsâ€”Chicago School thinking that essentially says vertical mergers (buying companies in different parts of the supply chain) are rarely harmful.\nThe economists said Google would need to meet five extremely specific conditions to abuse this power. The conditions were so narrow, so theoretical, that proving harm became nearly impossible. It\u0026rsquo;s like designing a murder investigation where you can only convict if the killer used a left-handed screwdriver on a Tuesday during a full moon.\nHere\u0026rsquo;s what actually happened: Google integrated DoubleClick into its systems, engaged in systematic self-preferencing, and built a monopoly so complete that by 2025, the European Commission fined them â‚¬2.95 billion for \u0026ldquo;favouring its own online display advertising technology services to the detriment of competing providers.\u0026rdquo;\nTranslation: everyone who warned about this in 2007 was right. The economists were catastrophically wrong.\nThe Fitbit Fiasco You\u0026rsquo;d think regulators would learn. They didn\u0026rsquo;t.\nIn 2020, Google bought Fitbit for $2.1 billion. Again, concerns were raised about data privacy and market power. Again, regulators approved itâ€”this time with \u0026ldquo;behavioral commitments\u0026rdquo; that were supposed to prevent Google from abusing its new position.\nHere\u0026rsquo;s what Google promised: they wouldn\u0026rsquo;t use Fitbit health data for ads, they\u0026rsquo;d keep APIs open for competitors, they\u0026rsquo;d play nice with Android integration.\nHere\u0026rsquo;s what actually happened: Fitbit lost users, generated less revenue, saw device sales plummet. Google launched its own competing Pixel Watch. Fitbit\u0026rsquo;s web dashboard shut down. The co-founders left. By 2025, Google announced it\u0026rsquo;s selling Verily, its health data subsidiary, suggesting they never had serious intentions for the health data business anyway.\nThe commitments became irrelevant because the product withered. No one wrote rules against killing what you acquire. The economists had a term for thisâ€”\u0026ldquo;killer acquisitions\u0026rdquo;â€”but their theoretical frameworks still couldn\u0026rsquo;t catch it in practice.\nThe Vertical Power Blind Spot Here\u0026rsquo;s what makes this so insidious: traditional antitrust thinking focuses on horizontal powerâ€”one company dominating a single market. Smartphone makers competing with smartphone makers. Search engines competing with search engines.\nBut digital platforms operate vertically. Google doesn\u0026rsquo;t just compete in searchâ€”it owns the ad exchange, the ad server, the analytics, the browser, the operating system, the cloud infrastructure, and increasingly, the AI models that power everything. It\u0026rsquo;s the NYSE, Goldman Sachs, and the SEC all rolled into one.\nOne Google official in 2016 compared their position to \u0026ldquo;Goldman or Citibank owning the NYSE.\u0026rdquo; They knew exactly what they were building.\nThe Chicago School framework systematically misses this. It\u0026rsquo;s designed to catch companies that raise prices. But Google gives away most products for free. The harm shows up in data exploitation, innovation suppression, privacy erosion, and the slow strangulation of potential competitors before they ever become threats.\nAn economist would need to prove five cumulative conditions to block a vertical merger. A mafia don just needs to make you an offer you can\u0026rsquo;t refuse.\nThe Geopolitical Twist Here\u0026rsquo;s where it gets properly disturbing. Google\u0026rsquo;s influence has become so vast that it\u0026rsquo;s essentially merged with U.S. geopolitical interests.\nCommerce Secretary Howard Lutnick said in March 2025: \u0026ldquo;I go to the heads of Google and Microsoft and Amazon. They\u0026rsquo;re all for America, building for us.\u0026rdquo; He\u0026rsquo;s openly describing a strategy where American tech dominance is a tool of state power.\nGoogle\u0026rsquo;s former CEO Eric Schmidt chairs government AI committees. The company has embedded itself so deeply in national infrastructure that opposing it feels almost unpatriotic. This creates a doom loop: the more powerful Google becomes, the harder it is to regulate, which makes it more powerful.\nNow they want to acquire Wiz, a $32 billion Israeli cybersecurity company that gives visibility across multiple clouds. If approved, Google would have invasive, real-time access to the internal operations of businesses worldwide. For a company that pioneered \u0026ldquo;surveillance capitalism,\u0026rdquo; this should terrify everyone.\nThe Numbers Don\u0026rsquo;t Lie Let\u0026rsquo;s zoom out to the full picture:\nBetween 2014-2024, Google\u0026rsquo;s investments dwarfed every competitor. In 2022 alone, Google invested in 743 companiesâ€”more than Amazon, Apple, Meta, and Microsoft combined. Most of this came through Google for Startups, which provides funding, cloud credits, and \u0026ldquo;support\u0026rdquo; to young companies.\nSupport. That\u0026rsquo;s the euphemism. What it really means: Google identifies promising innovations early, makes them dependent on Google infrastructure, shapes their business models to align with Google\u0026rsquo;s interests, and creates a network of nominally independent companies that all feed data and intelligence back to Mountain View.\nThis doesn\u0026rsquo;t trigger merger reviews. It doesn\u0026rsquo;t show up in market share calculations. It doesn\u0026rsquo;t appear in most academic studies of big tech power. But it\u0026rsquo;s arguably more powerful than any acquisition could be.\nThe researchers analyzed PitchBook dataâ€”which tracks private markets better than public market dataâ€”and found Google has invested in or supported nearly 6,000 companies since 2010. Not acquired. Invested in. Supported. Influenced. Shaped.\nThat\u0026rsquo;s not a company. That\u0026rsquo;s an empire.\nThe Bullshit Detector Let\u0026rsquo;s be clear about what this paper gets right and where we should be skeptical.\nWhat\u0026rsquo;s solid: The data on Google\u0026rsquo;s investment strategy is unprecedented. PitchBook captures transactions that Bloomberg and other public-market trackers miss. The comparison showing Google out-investing all other GAFAM companies combined is striking and appears robust.\nThe critique of Chicago School economics is devastating and well-documented. The DoubleClick and Fitbit case studies show clear regulatory failures where concerns raised in real-time proved prophetic.\nWhere to push back: The paper doesn\u0026rsquo;t fully distinguish between different types of \u0026ldquo;support.\u0026rdquo; Getting free cloud credits is different from receiving equity investment. The 6,000 number lumps these together. How many of those companies are truly dependent versus just opportunistically taking free stuff?\nAlso, the paper is explicitly advocating for policy change (structural remedies, prohibiting mergers). That\u0026rsquo;s fineâ€”academics should advocateâ€”but readers should know the authors have a position. They want more aggressive antitrust enforcement. I happen to think they\u0026rsquo;re right, but you should know where they\u0026rsquo;re coming from.\nThe geopolitical angle, while concerning, relies heavily on one Commerce Secretary quote. More evidence of government-Google alignment would strengthen this section.\nWhat This Actually Means If you\u0026rsquo;re a startup founder, you probably already feel this. That attractive Google for Startups program? Those \u0026ldquo;free\u0026rdquo; cloud credits? They\u0026rsquo;re not charity. They\u0026rsquo;re the first link in a chain of dependencies.\nIf you\u0026rsquo;re concerned about competition, this should radicalize you. Traditional antitrust can\u0026rsquo;t catch this. The rules were written for Standard Oil and AT\u0026amp;Tâ€”horizontal monopolies that raised prices. Google built something different: a vertical empire that gives away products while extracting data, suppressing innovation, and making independent competition structurally impossible.\nIf you\u0026rsquo;re European (or non-American), this should terrify you. Your digital infrastructure is controlled by an American company that the U.S. government increasingly treats as an instrument of national power. The Trump administration created a \u0026ldquo;National Energy Dominance Council.\u0026rdquo; They\u0026rsquo;re thinking the same way about technology dominance.\nThe researchers end with a call for new analytical toolsâ€”using accounting and financial analysis instead of Industrial Organization economics to understand vertical power. They want structural remedies (breaking up companies) instead of behavioral commitments (promising to be good).\nMost importantly, they identify Google\u0026rsquo;s proposed Wiz acquisition as the test case. Will regulators finally learn from past mistakes? Or will they wave through another deal using the same failed framework?\nThe Wonder Moment Here\u0026rsquo;s what keeps me up: Google\u0026rsquo;s strategy is brilliant in a terrifying way. They found the gap between what regulators can see and what actually matters. They shifted from buying companies (visible, regulable) to building dependencies (invisible, everywhere).\nIt\u0026rsquo;s rather remarkable, actually, how completely they\u0026rsquo;ve outmaneuvered democratic oversight. Not through corruption or illegality, but through structural innovation in how corporate power operates.\nThe question isn\u0026rsquo;t whether Google is too powerful. The question is whether we have any institutional capacity left to address power that operates this way.\nI don\u0026rsquo;t know the answer to that. But I know we\u0026rsquo;re about to find out.\nRead the Original Google\u0026rsquo;s hidden empire: New data reveals the company\u0026rsquo;s unexpected reach and the failure of antitrust authorities wielding Chicago-School economics to address vertical power by Aline Blankertz, Brianna Rock, and Nicholas Shaxson (2025)\nðŸ“„ Read it here: https://arxiv.org/pdf/2511.02931.pdf\narXiv:2511.02931v1 [cs.CY] 4 Nov 2025\n","permalink":"https://otechai.github.io/posts/2511.02931/","summary":"\u003ch1 id=\"googles-hidden-empire-when-dont-be-evil-built-6000-tentacles\"\u003eGoogle\u0026rsquo;s Hidden Empire: When \u0026ldquo;Don\u0026rsquo;t Be Evil\u0026rdquo; Built 6,000 Tentacles\u003c/h1\u003e\n\u003cp\u003eHere\u0026rsquo;s a question that should keep you up at night: What if the most powerful company in digital history isn\u0026rsquo;t just buying competitorsâ€”it\u0026rsquo;s building an invisible web of dependencies that regulators can\u0026rsquo;t even see?\u003c/p\u003e\n\u003cp\u003eThree researchers just dropped a bombshell paper revealing that Google has quietly amassed control over nearly 6,000 companies through investments and \u0026ldquo;support.\u0026rdquo; Not acquisitions. Support. Like a friendly neighborhood loan shark, except the neighborhood is the entire internet and the \u0026ldquo;loan\u0026rdquo; comes with strings attached to your innovation pipeline.\u003c/p\u003e","title":"Google's Hidden Empire: When `Don't Be Evil` Built 6,000 Tentacles"},{"content":"Slopaganda: When AI Becomes a Weapon for Your Mind Here\u0026rsquo;s what should terrify you: News Corp Australia churns out 3,000 AI-generated \u0026ldquo;local\u0026rdquo; news stories every week. Not written by journalists. Generated by algorithms. And they\u0026rsquo;re getting better at lying than humans are.\nLet me think about this for a moment. We\u0026rsquo;ve always had propaganda. Goebbels had his radio broadcasts. Napoleon had his pamphlets. The Catholic Church had its missionaries. But something fundamentally different is happening now, and three researchers just mapped out exactly how screwed we might be.\nThey Call It \u0026ldquo;Slopaganda.\u0026rdquo; Here\u0026rsquo;s What That Really Means. The term is newâ€”a mashup of \u0026ldquo;slop\u0026rdquo; (unwanted AI-generated garbage) and \u0026ldquo;propaganda\u0026rdquo; (intentional belief manipulation for political ends). But don\u0026rsquo;t let the silly name fool you. This is the difference between a knife and a nuclear weapon.\nTraditional propaganda had limits. You needed printing presses, radio stations, TV networks. You broadcast the same message to everyone. It was expensive. It was slow. And sophisticated people could spot it.\nSlopaganda? It knows you. It knows what time you\u0026rsquo;re awake. It knows your zip code, your commute length, which Facebook pages you liked five years ago. It can generate personalized messages faster than you can read them. And here\u0026rsquo;s the beautiful, terrible thing: it doesn\u0026rsquo;t just lie. It tells you exactly what you already half-believe, wrapped in language that feels local, familiar, true.\nYour Brain Is Playing Checkers. Slopaganda Is Playing 4D Chess. Let\u0026rsquo;s talk about how your brain actually makes decisions, because the paper\u0026rsquo;s authorsâ€”cognitive scientists who study this stuffâ€”lay it out with surgical precision.\nDecision-making isn\u0026rsquo;t some magical moment of free will. It\u0026rsquo;s a multi-stage process that uses accumulated information at every step. When that information is correct, you make good choices and feel a strong sense of agency. When it\u0026rsquo;s wrong? You make bad decisions and don\u0026rsquo;t even realize why.\nNow here\u0026rsquo;s where it gets interesting. Your brain has gatekeepersâ€”attention and memory systems that decide what information matters enough to store. And these systems are hilariously easy to hijack.\nThe Attention Economy Problem: You\u0026rsquo;re drowning in information. There\u0026rsquo;s no possible way to process it all. So your brain has a simple rule: pay attention to threats. Makes sense evolutionarilyâ€”better to have a thousand false alarms than miss one tiger.\nSlopaganda exploits this mercilessly. Feed people threatening content targeted to their specific fears, and boomâ€”it captures attention. Gets encoded in memory. Influences decisions for years.\nThe Emotional Amplifier: Your brain remembers negative information better. It\u0026rsquo;s called negativity bias. You remember insults more vividly than compliments. Threats more than comforts. Violence more than peace.\nAI can now generate an endless stream of emotionally-charged, threatening messages customized to your psychological profile. Worried about justice? Here\u0026rsquo;s AI-generated content about injustice in your area. Concerned about harm? Here are fabricated stories about violence near you.\nThe Confirmation Trap: Here\u0026rsquo;s the really nasty part. When you encounter information that conflicts with your beliefs, you reject it with negative emotion. When you encounter information that confirms what you already think? Your brain lights up like a Christmas tree. \u0026ldquo;Yes! I knew it!\u0026rdquo;\nResearchers tested this. They can now microtarget content that reinforces your existing biases while hiding alternative perspectives. It\u0026rsquo;s not even that hard.\nThe Continued Influence Effect (Or: Why Correcting Lies Doesn\u0026rsquo;t Work) You know what\u0026rsquo;s genuinely disturbing? When researchers correct false information in people\u0026rsquo;s brains, traces of the original lie persist. Like trying to delete text from a documentâ€”the words disappear, but the indent remains.\nPicture this: You read an AI-generated story claiming a politician took bribes. Later, you learn it was false. But your brain still has that politician filed under \u0026ldquo;corrupt.\u0026rdquo; The correction doesn\u0026rsquo;t erase the neural pathway. It just adds a competing one.\nNow multiply this by thousands of personalized messages per day, targeted to millions of people. Even if fact-checkers catch 90% of it (they won\u0026rsquo;t), the remaining 10% leaves permanent traces. Small effects at scale swing elections. Undermine public health. Start wars.\nThree Ways Slopaganda Is Different From Everything Before Scale: AI produces content faster than any human or content farm ever could. Orders of magnitude faster.\nScope: Personalization at the individual level. Not just \u0026ldquo;local news\u0026rdquo; but \u0026ldquo;news calibrated to your psychological profile, delivered when you\u0026rsquo;re most vulnerable.\u0026rdquo;\nSpeed: Hyper-connected social networks plus algorithmic amplification. A lie circles the globe before truth puts on its shoes.\nThe paper\u0026rsquo;s authors invoke \u0026ldquo;Brandolini\u0026rsquo;s Law\u0026rdquo;â€”it takes ten times more energy to refute bullshit than to produce it. Slopaganda just made that ratio 100 to 1. Maybe 1,000 to 1.\nReal Examples That Should Worry You Sinclair Media owned dozens of \u0026ldquo;local\u0026rdquo; news stations across America. One day, someone noticed all these supposedly independent local anchors were reading the exact same script, word for word. \u0026ldquo;This is extremely dangerous to our democracy,\u0026rdquo; they all intoned, identically.\nThat was 2018. Pre-AI. Now imagine that but personalized, generated at scale, impossible to trace back to a single script.\nSteve Bannon, founder of Breitbart News, bragged his strategy was to \u0026ldquo;flood the zone with shit.\u0026rdquo; Researchers found Breitbart had a semantic tag called \u0026ldquo;Black Crime\u0026rdquo; (no corresponding \u0026ldquo;White Crime\u0026rdquo; tag, naturally). Half a dozen sensationalistic stories designed to create racial associations in readers\u0026rsquo; brains.\nThat was before generative AI. Imagine flooding the zone with a million pieces of racially-charged shit per day, each one calibrated to its reader\u0026rsquo;s existing prejudices.\nDuring the 2024 US election, Trump posted AI-generated images suggesting Taylor Swift endorsed him. Elon Musk posted deepfake audio of Kamala Harris saying embarrassing things she never said. These were one-offs. The real danger is when this becomes industrialized, automated, personalized.\nThe Illusory Truth Effect (Or: How Repetition Becomes Reality) Here\u0026rsquo;s a psychological phenomenon that makes all of this worse: if you hear something repeated enough times, your brain starts treating it as true. Doesn\u0026rsquo;t matter if it\u0026rsquo;s false. Familiarity becomes a cue for truthfulness.\nGoebbels supposedly said, \u0026ldquo;Repeat a lie often enough, and it becomes the truth.\u0026rdquo; The researchers note this is probably apocryphalâ€”but the principle is scientifically validated.\nNow give that principle to AI that can generate personalized content at infinite scale and speed. You\u0026rsquo;ll see the same narrative surface repeatedly in your feed, from \u0026ldquo;different\u0026rdquo; sources, all generated by the same system. Your brain never stood a chance.\nWhat Can We Do? (Spoiler: Nothing Easy) The paper\u0026rsquo;s authors are honest about how hard this problem is. They suggest:\nPsychological interventions: Games like \u0026ldquo;Bad News\u0026rdquo; that let people practice spotting manipulation tactics. Digital literacy education. Journaling exercises to build intellectual humility. These work. Small effects. High cost. Not enough.\nTechnological solutions: AI detection tools. Content moderation systems. Browser plugins that encourage self-reflection. Better recommendation algorithms. The challenge? Every defense creates an arms race. The offense has more resources.\nEconomic and political interventions: Here\u0026rsquo;s where the authors get bold. They point out that oligarchs with more money than they could ever spend are using their wealth to pollute the information ecosystem. Their suggestion? A global wealth tax to reduce oligarchic power and fund counter-measures.\nRather remarkable, actuallyâ€”academic researchers proposing wealth redistribution as a solution to an epistemology problem. But they\u0026rsquo;re not wrong. The problem isn\u0026rsquo;t just cognitive. It\u0026rsquo;s material. It\u0026rsquo;s about who has power.\nThe Beautiful, Terrible Truth Slopaganda represents a phase change in how power operates. It\u0026rsquo;s not just propaganda getting better. It\u0026rsquo;s a qualitatively new phenomenonâ€”targeting meets personalization meets scale meets speed meets psychological sophistication.\nSmall effects at large scale, delivered with precision to people in their moments of vulnerability, accumulating as neural traces that persist even after correctionâ€”this is the epistemic environment we now inhabit.\nThe authors conclude with something I find both inspiring and depressing: we need to be bold enough to propose solutions that seem impossible, because the status quo is untenable. \u0026ldquo;Infeasibility is often cynically used as an objection by those who benefit unjustly from the status quo.\u0026rdquo;\nIn other words: yeah, global wealth taxes seem impossible. So does living in a world where truth matters. Pick your impossibility.\nThe Part They Don\u0026rsquo;t Want You To Know Sample sizes matter. Funding sources matter. Replication matters. This paper is a conceptual analysis with literature reviewâ€”not an experimental study. The authors are synthesizing existing research on cognitive science, AI capabilities, and propaganda to argue that slopaganda is a unique threat.\nAre they right? The evidence they marshal is compelling. The mechanisms they describe are well-established. But we\u0026rsquo;re still in early days. We don\u0026rsquo;t yet have longitudinal studies showing slopaganda\u0026rsquo;s long-term effects.\nWhat we do have: AI systems that are provably better at producing persuasive disinformation than humans. Platforms deploying these systems at scale. Evidence that microtargeting works. And a political economy that rewards flooding zones with shit.\nThat\u0026rsquo;s not proof. But it\u0026rsquo;s a rather concerning convergence of factors, actually.\nRead the Original Slopaganda: The interaction between propaganda and generative AI by MichaÅ‚ Klincewicz, Mark Alfano, and Amir Ebrahimi Fard (2025)\nðŸ“„ Read it here: https://arxiv.org/pdf/2503.01560.pdf\nThe beautiful thing about science is that it gives us tools to understand threats before they destroy us. The terrible thing is we have to choose to use those tools. Your move.\n","permalink":"https://otechai.github.io/posts/2503.01560/","summary":"\u003ch1 id=\"slopaganda-when-ai-becomes-a-weapon-for-your-mind\"\u003eSlopaganda: When AI Becomes a Weapon for Your Mind\u003c/h1\u003e\n\u003cp\u003eHere\u0026rsquo;s what should terrify you: News Corp Australia churns out 3,000 AI-generated \u0026ldquo;local\u0026rdquo; news stories every week. Not written by journalists. Generated by algorithms. And they\u0026rsquo;re getting better at lying than humans are.\u003c/p\u003e\n\u003cp\u003eLet me think about this for a moment. We\u0026rsquo;ve always had propaganda. Goebbels had his radio broadcasts. Napoleon had his pamphlets. The Catholic Church had its missionaries. But something fundamentally different is happening now, and three researchers just mapped out exactly how screwed we might be.\u003c/p\u003e","title":"Slopaganda: When AI Becomes a Weapon for Your Mind"}]