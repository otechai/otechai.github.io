<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Threat Modeling and Why "I Have Nothing to Hide" Is Bollocks - Blog post">
    <meta name="keywords" content="blog, article, Threat Modeling and Why "I Have Nothing to Hide" Is Bollocks">
    <meta name="author" content="My Blog">
    <meta property="og:title" content="Threat Modeling and Why "I Have Nothing to Hide" Is Bollocks">
    <meta property="og:description" content="Threat Modeling and Why "I Have Nothing to Hide" Is Bollocks - Blog post">
    <meta property="og:type" content="article">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Threat Modeling and Why "I Have Nothing to Hide" Is Bollocks">
    <meta name="twitter:description" content="Threat Modeling and Why "I Have Nothing to Hide" Is Bollocks - Blog post">
    <meta name="theme-color" content="#667eea">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="default">
    <link rel="manifest" href="../data/manifest.json">
    <title>Threat Modeling and Why "I Have Nothing to Hide" Is Bollocks</title>
    <link rel="icon" type="image/png" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'%3E%3Ctext y='0.9em' font-size='90'%3Eüìù%3C/text%3E%3C/svg%3E">
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-XXXXXXXXXX');
    </script>

    <link rel="stylesheet" href="../styles/posts.css">
</head>
<body>
    <a href="../index.html" class="back-link">‚Üê Back to home</a>
    <article>
        <h1>Threat Modeling and Why "I Have Nothing to Hide" Is Bollocks</h1>
<p>"I have nothing to hide."</p>
<p>You've said it. I've said it. Your nan's probably said it while handing her phone to a policeman asking to see her photos from the garden centre. It's the reflexive response when someone mentions privacy, surveillance, or encryption. It sounds reasonable. It feels like the position of someone with a clear conscience.</p>
<p>It's also complete nonsense, and understanding why requires grasping a concept that sounds more complicated than it is: threat modeling.</p>
<h2>What Threat Modeling Actually Is</h2>
<p>Threat modeling is simply asking: "What am I protecting, from whom, and what are they capable of?"</p>
<p>That's it. No complicated formulas, no security doctorate required. It's the same thinking you do when you lock your front door‚Äîyou're protecting your stuff from opportunistic burglars, who are capable of trying the handle but probably won't bring a battering ram.</p>
<p>You don't leave your door unlocked just because "I have nothing worth stealing." You recognize that someone else gets to decide what's worth taking, and more importantly, that an unlocked door invites problems you haven't imagined. The burglar might not want your telly‚Äîthey might want a place to hide from police, or to use your address for fraud, or simply to trash the place because they're having a bad day.</p>
<p>Privacy works the same way. When you say "I have nothing to hide," you're making several massive assumptions:</p>
<ol>
<li>You know everything that could be used against you</li>
<li>You trust who has access to your information now</li>
<li>You trust who will have access to it in the future</li>
<li>You trust that the rules won't change</li>
<li>You're okay with anyone making decisions about your life based on information you don't control</li>
</ol>
<p>Every single one of these assumptions is wrong.</p>
<h2>The Threat Isn't Always Who You Think</h2>
<p>Let's do a proper threat model, shall we? Start with a simple question: who might want information about you?</p>
<p><strong>Your employer.</strong> Are you looking at other job listings during lunch? Complaining about management in a WhatsApp group? Your location data could reveal you're interviewing at competitors. Your browsing history could suggest you're researching workers' rights before filing a complaint.</p>
<p><strong>Your insurance company.</strong> Health searches reveal pre-existing conditions. Location data shows whether you frequent gyms or fast food restaurants. Social media posts indicate risky hobbies. They're not evaluating your health‚Äîthey're calculating whether to deny your claim.</p>
<p><strong>Your government.</strong> Not just the current one, but future ones. That protest you attended? The political organization you donated to? The religious service you streamed? Perfectly legal today. Ask the Uyghurs in China how that worked out. Ask Japanese-Americans interned in 1942. Ask anyone who's watched their country slide from democracy to authoritarianism whether historical data about "dissidents" gets weaponized.</p>
<p><strong>Your ex-partner.</strong> Who knows your routines, your passwords, your security questions. Domestic abuse increasingly involves stalkerware, GPS tracking, and hacked accounts. "I have nothing to hide" becomes "they know where I am every moment" becomes "I can't leave safely."</p>
<p><strong>Data brokers you've never heard of.</strong> Companies that aggregate your information from thousands of sources and sell it to anyone with a credit card. They know your income, your politics, your health conditions, your sexual orientation, your shopping habits. They sell "sucker lists" of vulnerable people to scammers. They provide data to ICE for deportation raids. They leak databases to criminals.</p>
<p><strong>Criminals.</strong> Identity thieves need your personal information. Ransomware gangs need to know your business operations. Scammers need to know your vulnerabilities. SIM swappers need your phone provider details. They're not judging your morality‚Äîthey're calculating your exploitability.</p>
<p><strong>Future you.</strong> That embarrassing photo? That drunken rant? That poorly aged opinion? The internet doesn't forget. Your data will outlive your current context, your current job, your current relationship, your current beliefs. You're creating a permanent record of your worst moments for an audience that doesn't know you.</p>
<p>This isn't paranoia. This is just listing the established players in the data economy. And we haven't even gotten to the exotic threats: authoritarian regimes buying data on dissidents abroad, stalkers using leaked location data, AI systems making consequential decisions based on proxies for race or class or disability.</p>
<h2>The Problem With Perfect Behavior</h2>
<p>"But I don't do anything wrong!" you say.</p>
<p>Right. Let's test that.</p>
<p>Have you ever:<br />
- Exceeded the speed limit?<br />
- Jaywalked?<br />
- Shared a Netflix password?<br />
- Downloaded a PDF of a journal article behind a paywall?<br />
- Lied on a dating app about your age or height?<br />
- Called in sick when you weren't?<br />
- Fudged numbers on a tax return?<br />
- Smoked weed where it's illegal?<br />
- Had a drink before driving the next morning?<br />
- Broken a terms of service agreement you never read?</p>
<p>The average person commits roughly three felonies a day without knowing it, according to civil liberties lawyer Harvey Silverglate. Not because we're criminals, but because the law is vast, contradictory, and selectively enforced. The question isn't whether you've done something technically illegal‚Äîyou have. The question is whether anyone with power decides to care.</p>
<p>This is why "nothing to hide" is such a dangerous position. It assumes the rules are clear, fair, and consistently applied. They're not. It assumes you're being judged by objective criteria. You're not. It assumes good faith from institutions that have demonstrated, repeatedly, that they do not operate in good faith.</p>
<h2>How Information Gets Weaponized</h2>
<p>Here's a case study in threat modeling: a woman in Nebraska was prosecuted for helping her daughter obtain abortion pills. How did authorities know? Facebook handed over their private messages. The company that promises to "connect friends and family" delivered the evidence for felony charges.</p>
<p>The threat model failed at every level:<br />
- <strong>Asset:</strong> Private conversations about healthcare<br />
- <strong>Threat actor:</strong> State government in a post-Roe America<br />
- <strong>Capability:</strong> Warrant power over tech companies with no meaningful resistance</p>
<p>The woman probably thought she had nothing to hide. Abortion pills were legal when she bought them. The conversation was private between mother and daughter. Neither of them was a criminal in any meaningful sense. And yet.</p>
<p>Or consider: you're job hunting. A potential employer runs a background check through a data broker. The broker's AI flags you as "high risk" because you live in a neighborhood correlated with financial instability, visit websites correlated with depression, and have a friend who was arrested (charges dropped). You don't get the job. You never know why. You can't appeal. You can't see the data. The decision is automated, invisible, and devastating.</p>
<p>This is the actual threat model most people face. Not the FBI kicking down your door, but opaque systems making consequential decisions based on data you didn't know was being collected, using criteria you don't understand, with no recourse when they get it wrong.</p>
<h2>The Shifting Goalposts Problem</h2>
<p>Even if you're squeaky clean today, the rules change.</p>
<p>Homosexuality was illegal in the UK until 1967. The government kept lists of suspected homosexuals. When the law changed, did they destroy those lists? Did they apologize to the people whose lives they'd ruined? Of course not.</p>
<p>Marijuana use can still disqualify you from jobs, even in states where it's legal. Historical data about purchases, medical cards, or social media posts creates permanent records that outlast the legal context.</p>
<p>The data you're generating today will be judged by tomorrow's standards, tomorrow's governments, tomorrow's employers, tomorrow's algorithms. You're not just answering for your current behavior‚Äîyou're creating evidence that will be interpreted by systems you can't predict, using values you might not share, for purposes you can't imagine.</p>
<h2>The Asymmetry of Power</h2>
<p>Here's the real reason "nothing to hide" is bollocks: the conversation isn't between equals.</p>
<p>When a cop says "if you have nothing to hide, you won't mind if I search your car," they're not offering a mutual exchange. They're not saying "I'll let you search my police records while I search your vehicle." They're demanding asymmetric access to information.</p>
<p>When Facebook says "we need your real name to connect you with friends," they're not showing you their algorithmic manipulation strategies or their data broker partnerships. They're not giving you access to their internal communications about how to maximize engagement even when it harms users.</p>
<p>When your employer says "we need to monitor your computer for security," they're not letting you monitor their financial decisions or internal discussions about your compensation.</p>
<p>The entire premise of "nothing to hide" only works if everyone has equal access to everyone else's information. But surveillance is inherently asymmetric. Those with power demand transparency from those without it, while operating in secrecy themselves.</p>
<p>This is why privacy matters even if you're perfectly innocent. Because privacy is the ability to control your own narrative, to make mistakes without permanent consequences, to be vulnerable without being exploited, to be different without being punished. It's the right to be imperfect in an imperfect world.</p>
<h2>Building Your Threat Model</h2>
<p>So what's the alternative to "nothing to hide"? Actual threat modeling.</p>
<p>Ask yourself:<br />
1. <strong>What information do I generate?</strong> Location data, communications, financial transactions, health records, browsing history, social connections, opinions, photos, documents. All of it is data.</p>
<ol start="2">
<li>
<p><strong>Who has access?</strong> Not just who you've explicitly shared with, but who has technical access. Your phone company. Your email provider. Your employer's IT department. App developers. Advertisers. Government agencies with warrants (or without). Hackers who find vulnerabilities.</p>
</li>
<li>
<p><strong>What could they do with it?</strong> Not just malicious uses, but unintended ones. Deny you services. Discriminate against you. Manipulate you. Steal from you. Embarrass you. Misjudge you. Make automated decisions about your life.</p>
</li>
<li>
<p><strong>What are the consequences?</strong> Job loss. Relationship damage. Financial harm. Physical danger. Reputational destruction. Legal jeopardy. Psychological distress.</p>
</li>
<li>
<p><strong>What's proportional protection?</strong> You don't need to live in a Faraday cage. But you should encrypt sensitive communications. Use a password manager. Enable two-factor authentication. Understand what you're sharing and with whom.</p>
</li>
</ol>
<p>This isn't paranoia. It's basic risk management. You lock your door not because burglars are definitely coming, but because the cost of locking is low and the cost of not locking is potentially catastrophic. Same logic applies to digital security.</p>
<h2>The Dignity Argument</h2>
<p>Here's something the "nothing to hide" crowd misses entirely: privacy isn't about hiding bad things. It's about protecting human dignity.</p>
<p>You close the bathroom door not because defecation is wrong, but because some things are private even when they're perfectly normal. You have conversations with your therapist not because you're broken, but because vulnerability requires safe spaces. You don't publish your diary not because you've done anything shameful, but because intimacy requires boundaries.</p>
<p>Privacy is the space where you can be uncertain, make mistakes, change your mind, be contradictory, be human. It's where you can think without performing, feel without justifying, exist without optimizing for an audience.</p>
<p>Surveillance doesn't just collect data‚Äîit changes behavior. When you know you're being watched, you self-censor. You perform normalcy. You sand down your edges. You become the person you think the watchers want you to be.</p>
<p>This is the panopticon effect: you don't need to be watched constantly if you think you might be watched at any moment. The possibility of surveillance is enough to control behavior. And a society of people constantly performing for invisible watchers is not a free society.</p>
<h2>The Collective Harm</h2>
<p>Even if you personally don't care about privacy, your data harms others.</p>
<p>Your contact list exposes your friends. Your location data reveals patterns that can be used to surveil others. Your metadata contributes to profiles used to target vulnerable populations. Your acceptance of invasive terms of service makes it harder for others to opt out.</p>
<p>Privacy is a collective right, not just an individual one. When you say "I have nothing to hide," you're not just waiving your own rights‚Äîyou're degrading the privacy environment for everyone else. You're making it harder for journalists to protect sources, for activists to organize, for abuse survivors to stay safe, for anyone who does need privacy to have it without marking themselves as suspicious.</p>
<p>This is why privacy advocates get so frustrated with the "nothing to hide" argument. It's not just wrong individually‚Äîit's corrosive to collective rights. It normalizes surveillance, legitimizes data collection, and shifts the burden onto those who dare to resist.</p>
<h2>The Path Forward</h2>
<p>So, threat modeling. Not as some paranoid exercise in imagining worst-case scenarios, but as a practical framework for understanding risk and making informed choices.</p>
<p>You don't need to protect against every threat. You need to understand which threats are realistic for you, which harms would be most devastating, and which protections are proportional to those risks.</p>
<p>For most people, the threat model looks something like:<br />
- Protect against routine data breaches (password manager, 2FA)<br />
- Limit corporate surveillance (ad blockers, privacy-respecting apps)<br />
- Avoid creating permanent records of everything (think before you post)<br />
- Understand who has access to what (read privacy policies, use encryption when it matters)<br />
- Prepare for the rules to change (assume nothing is truly deleted)</p>
<p>This isn't about achieving perfect security‚Äîthat's impossible. It's about making surveillance expensive, making exploitation difficult, and maintaining some sphere of your life that belongs to you alone.</p>
<h2>The Real Question</h2>
<p>"I have nothing to hide" is the wrong framing. The right question isn't whether you have something to hide‚Äîit's whether you have something to protect.</p>
<p>Do you have thoughts you're still forming? Protect them.<br />
Do you have relationships you value? Protect them.<br />
Do you have mistakes you've made? Protect your ability to grow beyond them.<br />
Do you have vulnerabilities that could be exploited? Protect them.<br />
Do you have a self that exists outside of surveillance? Protect it.</p>
<p>Privacy isn't about being shady. It's about being human in a world that increasingly treats humans as data points to be optimized, exploited, and controlled.</p>
<p>So the next time someone says "I have nothing to hide," ask them: Are you sure? Do you know what you're revealing? Do you know who's watching? Do you trust them? Do you trust their successors? Do you want to live in a world where every mistake is permanent, every moment is recorded, every deviation from the norm is flagged?</p>
<p>Because that's the world we're building, one "I have nothing to hide" at a time.</p>
<p>Threat modeling is how you take back control. Not through paranoia, but through informed choices about what you protect, from whom, and why.</p>
<p>The door is unlocked. The question is: who are you inviting in?</p>
    </article>
    <footer>
        <p>&copy; 2025 <a href="https://www.linkedin.com/in/otmane-echaibi-90a524309/" target="_blank" rel="noopener noreferrer">Otmane Echaibi</a> | All Rights Reserved.</p>
    </footer>
    <button class="back-to-top" id="backToTop" onclick="scrollToTop()" title="Back to top">‚Üë</button>
    
    <script>
        // Back to top button functionality
        const backToTopButton = document.getElementById('backToTop');
        
        window.addEventListener('scroll', () => {
            if (window.pageYOffset > 300) {
                backToTopButton.classList.add('visible');
            } else {
                backToTopButton.classList.remove('visible');
            }
        });
        
        function scrollToTop() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        }
    </script>
</body>
</html>