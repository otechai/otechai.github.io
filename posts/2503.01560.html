<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Slopaganda: When AI Becomes a Weapon for Your Mind - Blog post">
    <meta name="keywords" content="blog, article, Slopaganda: When AI Becomes a Weapon for Your Mind">
    <meta name="author" content="My Blog">
    <meta property="og:title" content="Slopaganda: When AI Becomes a Weapon for Your Mind">
    <meta property="og:description" content="Slopaganda: When AI Becomes a Weapon for Your Mind - Blog post">
    <meta property="og:type" content="article">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Slopaganda: When AI Becomes a Weapon for Your Mind">
    <meta name="twitter:description" content="Slopaganda: When AI Becomes a Weapon for Your Mind - Blog post">
    <meta name="theme-color" content="#667eea">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="default">
    <link rel="manifest" href="../data/manifest.json">
    <title>Slopaganda: When AI Becomes a Weapon for Your Mind</title>
    <link rel="icon" type="image/png" href="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 100 100'%3E%3Ctext y='0.9em' font-size='90'%3Eüìù%3C/text%3E%3C/svg%3E">
    <!-- Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-XXXXXXXXXX');
    </script>

    <link rel="stylesheet" href="../styles/posts.css">
</head>
<body>
    <div class="post-header">
        <a href="../index.html" class="back-link">‚Üê Back to home</a>
        <div class="social-links">
        <a href="https://www.linkedin.com/in/otmane-echaibi-90a524309/" target="_blank" rel="noopener noreferrer" class="social-link linkedin" title="LinkedIn">
            <svg viewBox="0 0 24 24" width="20" height="20">
                <path fill="currentColor" d="M19 3a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h14m-.5 15.5v-5.3a3.26 3.26 0 0 0-3.26-3.26c-.85 0-1.84.52-2.32 1.3v-1.11h-2.79v8.37h2.79v-4.93c0-.77.62-1.4 1.39-1.4a1.4 1.4 0 0 1 1.4 1.4v4.93h2.79M6.88 8.56a1.68 1.68 0 0 0 1.68-1.68c0-.93-.75-1.69-1.68-1.69a1.69 1.69 0 0 0-1.69 1.69c0 .93.76 1.68 1.69 1.68m1.39 9.94v-8.37H5.5v8.37h2.77z"/>
            </svg>
        </a></div>
    </div>
    <article>
        <h1>Slopaganda: When AI Becomes a Weapon for Your Mind</h1>
<p>Here's what should terrify you: News Corp Australia churns out 3,000 AI-generated "local" news stories every week. Not written by journalists. Generated by algorithms. And they're getting better at lying than humans are.</p>
<p>Let me think about this for a moment. We've always had propaganda. Goebbels had his radio broadcasts. Napoleon had his pamphlets. The Catholic Church had its missionaries. But something fundamentally different is happening now, and three researchers just mapped out exactly how screwed we might be.</p>
<h2>They Call It "Slopaganda." Here's What That Really Means.</h2>
<p>The term is new‚Äîa mashup of "slop" (unwanted AI-generated garbage) and "propaganda" (intentional belief manipulation for political ends). But don't let the silly name fool you. This is the difference between a knife and a nuclear weapon.</p>
<p>Traditional propaganda had limits. You needed printing presses, radio stations, TV networks. You broadcast the same message to everyone. It was expensive. It was slow. And sophisticated people could spot it.</p>
<p>Slopaganda? It knows you. It knows what time you're awake. It knows your zip code, your commute length, which Facebook pages you liked five years ago. It can generate personalized messages faster than you can read them. And here's the beautiful, terrible thing: it doesn't just lie. It tells you exactly what you already half-believe, wrapped in language that feels local, familiar, true.</p>
<h2>Your Brain Is Playing Checkers. Slopaganda Is Playing 4D Chess.</h2>
<p>Let's talk about how your brain actually makes decisions, because the paper's authors‚Äîcognitive scientists who study this stuff‚Äîlay it out with surgical precision.</p>
<p>Decision-making isn't some magical moment of free will. It's a multi-stage process that uses accumulated information at every step. When that information is correct, you make good choices and feel a strong sense of agency. When it's wrong? You make bad decisions and don't even realize why.</p>
<p>Now here's where it gets interesting. Your brain has gatekeepers‚Äîattention and memory systems that decide what information matters enough to store. And these systems are hilariously easy to hijack.</p>
<p><strong>The Attention Economy Problem:</strong> You're drowning in information. There's no possible way to process it all. So your brain has a simple rule: pay attention to threats. Makes sense evolutionarily‚Äîbetter to have a thousand false alarms than miss one tiger.</p>
<p>Slopaganda exploits this mercilessly. Feed people threatening content targeted to their specific fears, and boom‚Äîit captures attention. Gets encoded in memory. Influences decisions for years.</p>
<p><strong>The Emotional Amplifier:</strong> Your brain remembers negative information better. It's called negativity bias. You remember insults more vividly than compliments. Threats more than comforts. Violence more than peace.</p>
<p>AI can now generate an endless stream of emotionally-charged, threatening messages customized to your psychological profile. Worried about justice? Here's AI-generated content about injustice in your area. Concerned about harm? Here are fabricated stories about violence near you.</p>
<p><strong>The Confirmation Trap:</strong> Here's the really nasty part. When you encounter information that conflicts with your beliefs, you reject it with negative emotion. When you encounter information that confirms what you already think? Your brain lights up like a Christmas tree. "Yes! I knew it!"</p>
<p>Researchers tested this. They can now microtarget content that reinforces your existing biases while hiding alternative perspectives. It's not even that hard.</p>
<h2>The Continued Influence Effect (Or: Why Correcting Lies Doesn't Work)</h2>
<p>You know what's genuinely disturbing? When researchers correct false information in people's brains, traces of the original lie persist. Like trying to delete text from a document‚Äîthe words disappear, but the indent remains.</p>
<p>Picture this: You read an AI-generated story claiming a politician took bribes. Later, you learn it was false. But your brain still has that politician filed under "corrupt." The correction doesn't erase the neural pathway. It just adds a competing one.</p>
<p>Now multiply this by thousands of personalized messages per day, targeted to millions of people. Even if fact-checkers catch 90% of it (they won't), the remaining 10% leaves permanent traces. Small effects at scale swing elections. Undermine public health. Start wars.</p>
<h2>Three Ways Slopaganda Is Different From Everything Before</h2>
<p><strong>Scale:</strong> AI produces content faster than any human or content farm ever could. Orders of magnitude faster.</p>
<p><strong>Scope:</strong> Personalization at the individual level. Not just "local news" but "news calibrated to your psychological profile, delivered when you're most vulnerable."</p>
<p><strong>Speed:</strong> Hyper-connected social networks plus algorithmic amplification. A lie circles the globe before truth puts on its shoes.</p>
<p>The paper's authors invoke "Brandolini's Law"‚Äîit takes ten times more energy to refute bullshit than to produce it. Slopaganda just made that ratio 100 to 1. Maybe 1,000 to 1.</p>
<h2>Real Examples That Should Worry You</h2>
<p>Sinclair Media owned dozens of "local" news stations across America. One day, someone noticed all these supposedly independent local anchors were reading the exact same script, word for word. "This is extremely dangerous to our democracy," they all intoned, identically.</p>
<p>That was 2018. Pre-AI. Now imagine that but personalized, generated at scale, impossible to trace back to a single script.</p>
<p>Steve Bannon, founder of Breitbart News, bragged his strategy was to "flood the zone with shit." Researchers found Breitbart had a semantic tag called "Black Crime" (no corresponding "White Crime" tag, naturally). Half a dozen sensationalistic stories designed to create racial associations in readers' brains.</p>
<p>That was before generative AI. Imagine flooding the zone with a million pieces of racially-charged shit per day, each one calibrated to its reader's existing prejudices.</p>
<p>During the 2024 US election, Trump posted AI-generated images suggesting Taylor Swift endorsed him. Elon Musk posted deepfake audio of Kamala Harris saying embarrassing things she never said. These were one-offs. The real danger is when this becomes industrialized, automated, personalized.</p>
<h2>The Illusory Truth Effect (Or: How Repetition Becomes Reality)</h2>
<p>Here's a psychological phenomenon that makes all of this worse: if you hear something repeated enough times, your brain starts treating it as true. Doesn't matter if it's false. Familiarity becomes a cue for truthfulness.</p>
<p>Goebbels supposedly said, "Repeat a lie often enough, and it becomes the truth." The researchers note this is probably apocryphal‚Äîbut the principle is scientifically validated.</p>
<p>Now give that principle to AI that can generate personalized content at infinite scale and speed. You'll see the same narrative surface repeatedly in your feed, from "different" sources, all generated by the same system. Your brain never stood a chance.</p>
<h2>What Can We Do? (Spoiler: Nothing Easy)</h2>
<p>The paper's authors are honest about how hard this problem is. They suggest:</p>
<p><strong>Psychological interventions:</strong> Games like "Bad News" that let people practice spotting manipulation tactics. Digital literacy education. Journaling exercises to build intellectual humility. These work. Small effects. High cost. Not enough.</p>
<p><strong>Technological solutions:</strong> AI detection tools. Content moderation systems. Browser plugins that encourage self-reflection. Better recommendation algorithms. The challenge? Every defense creates an arms race. The offense has more resources.</p>
<p><strong>Economic and political interventions:</strong> Here's where the authors get bold. They point out that oligarchs with more money than they could ever spend are using their wealth to pollute the information ecosystem. Their suggestion? A global wealth tax to reduce oligarchic power and fund counter-measures.</p>
<p>Rather remarkable, actually‚Äîacademic researchers proposing wealth redistribution as a solution to an epistemology problem. But they're not wrong. The problem isn't just cognitive. It's material. It's about who has power.</p>
<h2>The Beautiful, Terrible Truth</h2>
<p>Slopaganda represents a phase change in how power operates. It's not just propaganda getting better. It's a qualitatively new phenomenon‚Äîtargeting meets personalization meets scale meets speed meets psychological sophistication.</p>
<p>Small effects at large scale, delivered with precision to people in their moments of vulnerability, accumulating as neural traces that persist even after correction‚Äîthis is the epistemic environment we now inhabit.</p>
<p>The authors conclude with something I find both inspiring and depressing: we need to be bold enough to propose solutions that seem impossible, because the status quo is untenable. "Infeasibility is often cynically used as an objection by those who benefit unjustly from the status quo."</p>
<p>In other words: yeah, global wealth taxes seem impossible. So does living in a world where truth matters. Pick your impossibility.</p>
<h2>The Part They Don't Want You To Know</h2>
<p>Sample sizes matter. Funding sources matter. Replication matters. This paper is a conceptual analysis with literature review‚Äînot an experimental study. The authors are synthesizing existing research on cognitive science, AI capabilities, and propaganda to argue that slopaganda is a unique threat.</p>
<p>Are they right? The evidence they marshal is compelling. The mechanisms they describe are well-established. But we're still in early days. We don't yet have longitudinal studies showing slopaganda's long-term effects.</p>
<p>What we do have: AI systems that are provably better at producing persuasive disinformation than humans. Platforms deploying these systems at scale. Evidence that microtargeting works. And a political economy that rewards flooding zones with shit.</p>
<p>That's not proof. But it's a rather concerning convergence of factors, actually.</p>
<hr />
<h2>Read the Original</h2>
<p><strong>Slopaganda: The interaction between propaganda and generative AI</strong> by Micha≈Ç Klincewicz, Mark Alfano, and Amir Ebrahimi Fard (2025)<br />
üìÑ Read it here: https://arxiv.org/pdf/2503.01560.pdf</p>
<hr />
<p><em>The beautiful thing about science is that it gives us tools to understand threats before they destroy us. The terrible thing is we have to choose to use those tools. Your move.</em></p>
    </article>
    
    
    
    <footer>
        <p>&copy; 2025 <a href="https://www.linkedin.com/in/otmane-echaibi-90a524309/" target="_blank" rel="noopener noreferrer">Otmane Echaibi</a> | All Rights Reserved.</p>
    </footer>
    <button class="back-to-top" id="backToTop" onclick="scrollToTop()" title="Back to top">‚Üë</button>
    
    <script>
        // Back to top button functionality
        const backToTopButton = document.getElementById('backToTop');
        
        window.addEventListener('scroll', () => {
            if (window.pageYOffset > 300) {
                backToTopButton.classList.add('visible');
            } else {
                backToTopButton.classList.remove('visible');
            }
        });
        
        function scrollToTop() {
            window.scrollTo({
                top: 0,
                behavior: 'smooth'
            });
        }
    </script>
</body>
</html>